{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Install</h1></center>\n",
        "\n",
        "%cd /content\n",
        "!git clone -b totoro4 https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.28.post2\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "flux_version = \"dev\" # @param [\"dev\",\"schnell\"]\n",
        "\n",
        "if flux_version == \"schnell\":\n",
        "  !aria2c --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors -d /content/TotoroUI/models/unet -o flux1.safetensors\n",
        "elif flux_version == \"dev\":\n",
        "  !aria2c --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8.safetensors -d /content/TotoroUI/models/unet -o flux1.safetensors\n",
        "\n",
        "!aria2c --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae.sft\n",
        "!aria2c --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l.safetensors\n",
        "!aria2c --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /content/TotoroUI/models/clip -o t5xxl_fp8_e4m3fn.safetensors\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import nodes\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "from totoro_extras import nodes_custom_sampler\n",
        "from totoro_extras import nodes_post_processing\n",
        "from totoro_extras import nodes_flux\n",
        "from totoro import model_management\n",
        "from google.colab import files\n",
        "\n",
        "DualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\n",
        "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
        "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "FluxGuidance = nodes_flux.NODE_CLASS_MAPPINGS[\"FluxGuidance\"]()\n",
        "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "VAEEncode = NODE_CLASS_MAPPINGS[\"VAEEncode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "ImageScaleToTotalPixels = nodes_post_processing.NODE_CLASS_MAPPINGS[\"ImageScaleToTotalPixels\"]()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    clip = DualCLIPLoader.load_clip(\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "    unet = UNETLoader.load_unet(\"flux1.safetensors\", \"fp8_e4m3fn\")[0]\n",
        "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "\n",
        "    unet_f, clip_f = unet, clip\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <center><h1>Load/Unload Lora</h1></center>\n",
        "\n",
        "loras = {\n",
        "    \"xlabs_flux_anime\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/anime_lora_comfy_converted.safetensors\",\n",
        "         \"filename\": \"xlabs_anime_lora.safetensors\",\n",
        "         \"triggers\": \"anime\"\n",
        "         },\n",
        "    \"xlabs_flux_art\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/art_lora_comfy_converted.safetensors\",\n",
        "         \"filename\": \"xlabs_art_lora.safetensors\",\n",
        "         \"triggers\": \"art\"\n",
        "         },\n",
        "    \"xlabs_flux_disney\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/disney_lora_comfy_converted.safetensors\",\n",
        "         \"filename\": \"xlabs_disney_lora.safetensors\",\n",
        "         \"triggers\": \"disney style\"\n",
        "         },\n",
        "    \"xlabs_flux_mjv6_lora\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/mjv6_lora_comfy_converted.safetensors\",\n",
        "         \"filename\": \"xlabs_mjv6_lora.safetensors\",\n",
        "         \"triggers\": \"none\"\n",
        "         },\n",
        "    \"xlabs_flux_realism\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/realism_lora_comfy_converted.safetensors\",\n",
        "         \"filename\": \"xlabs_realism_lora.safetensors\",\n",
        "         \"triggers\": \"none\"\n",
        "         },\n",
        "    \"xlabs_flux_scenery\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/scenery_lora_comfy_converted.safetensors\",\n",
        "         \"filename\": \"xlabs_scenery_lora.safetensors\",\n",
        "         \"triggers\": \"scenery style\"\n",
        "         },\n",
        "    \"xlabs_flux_furry\":\n",
        "     {\n",
        "         \"url\": \"https://huggingface.co/XLabs-AI/flux-lora-collection/resolve/main/furry_lora.safetensors\",\n",
        "         \"filename\": \"xlabs_flux_furry_lora.safetensors\",\n",
        "         },\n",
        "}\n",
        "\n",
        "lora_name = \"no_lora\" # @param [\"no_lora\", \"xlabs_flux_anime\", \"xlabs_flux_art\", \"xlabs_flux_disney\", \"xlabs_flux_mjv6_lora\", \"xlabs_flux_realism\", \"xlabs_flux_scenery\"]\n",
        "lora_strength_model = 1 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "lora_strength_clip = 1 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.1}\n",
        "\n",
        "if lora_name == \"no_lora\":\n",
        "  unet_f, clip_f = unet, clip\n",
        "\n",
        "  print(\"Lora Unloaded\")\n",
        "else:\n",
        "  lora = loras.get(lora_name, None)\n",
        "\n",
        "  if lora:\n",
        "    !aria2c --download-result=hide --console-log-level=error --auto-file-renaming=false --allow-overwrite=false -c -x 16 -s 16 -k 1M {lora[\"url\"]} -d /content/TotoroUI/models/loras -o {lora[\"filename\"]}\n",
        "\n",
        "    unet_f, clip_f = LoraLoader.load_lora(unet, clip, lora[\"filename\"], lora_strength_model, lora_strength_clip)\n",
        "\n",
        "    print(f\"Lora Loaded: {lora['filename']}\")\n",
        "    print(f\"Triggers: {lora['triggers']}\")\n",
        "  else:\n",
        "    print(\"Lora is not listed\")"
      ],
      "metadata": {
        "id": "3AcAdyV-Absp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ur9TmMNwC2kR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Txt2Img</h1></center>\n",
        "\n",
        "with torch.inference_mode():\n",
        "    positive_prompt = \"black forest toast spelling out the words 'FLUX DEV', tasty, food photography, dynamic shot\" # @param {\"type\":\"string\"}\n",
        "    width = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "    height = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "    fixed_seed = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":18446744073709552000,\"step\":1}\n",
        "    guidance = 3.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":0.5}\n",
        "    steps = 20 # @param {\"type\":\"slider\",\"min\":4,\"max\":50,\"step\":1}\n",
        "    sampler_name = \"euler\" # @param [\"euler\",\"heun\",\"heunpp2\",\"heunpp2\",\"dpm_2\",\"lms\",\"dpmpp_2m\",\"ipndm\",\"deis\",\"ddim\",\"uni_pc\",\"uni_pc_bh2\"]\n",
        "    scheduler = \"simple\" # @param [\"normal\",\"sgm_uniform\",\"simple\",\"ddim_uniform\"]\n",
        "    batch_size = 1 # @param {\"type\":\"slider\",\"min\":1,\"max\":20,\"step\":1}\n",
        "    auto_download = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "    cond, pooled = clip_f.encode_from_tokens(clip_f.tokenize(positive_prompt), return_pooled=True)\n",
        "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "    cond = FluxGuidance.append(cond, guidance)[0]\n",
        "    guider = BasicGuider.get_guider(unet_f, cond)[0]\n",
        "    sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
        "    sigmas = BasicScheduler.get_sigmas(unet_f, scheduler, steps, 1.0)[0]\n",
        "    latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n",
        "\n",
        "    for i in range(0, batch_size):\n",
        "      if fixed_seed == 0:\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "      else:\n",
        "        seed = fixed_seed\n",
        "\n",
        "      print(\"Seed:\", seed)\n",
        "\n",
        "      noise = RandomNoise.get_noise(seed)[0]\n",
        "      sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
        "      model_management.soft_empty_cache()\n",
        "      decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "      Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"/content/flux_t2i_{seed}_{i}.png\")\n",
        "\n",
        "      if auto_download:\n",
        "        files.download(f\"/content/flux_t2i_{seed}_{i}.png\")\n",
        "\n",
        "      img = Image.open(f\"/content/flux_t2i_{seed}_{i}.png\")\n",
        "      display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Dpd2sfrePYoA"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h1>Img2Img</h1></center>\n",
        "\n",
        "with torch.inference_mode():\n",
        "    positive_prompt = \"anime style\" # @param {\"type\":\"string\"}\n",
        "    width = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "    height = 1024 # @param {\"type\":\"slider\",\"min\":256,\"max\":2048,\"step\":1}\n",
        "    fixed_seed = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":18446744073709552000,\"step\":1}\n",
        "    guidance = 3.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":0.5}\n",
        "    steps = 20 # @param {\"type\":\"slider\",\"min\":4,\"max\":50,\"step\":1}\n",
        "    sampler_name = \"euler\" # @param [\"euler\",\"heun\",\"heunpp2\",\"heunpp2\",\"dpm_2\",\"lms\",\"dpmpp_2m\",\"ipndm\",\"deis\",\"ddim\",\"uni_pc\",\"uni_pc_bh2\"]\n",
        "    scheduler = \"simple\" # @param [\"normal\",\"sgm_uniform\",\"simple\",\"ddim_uniform\"]\n",
        "    input_img = \"/content/test.png\" # @param {\"type\":\"string\"}\n",
        "    denoise = 0.85 # @param {\"type\":\"slider\",\"min\":0,\"max\":1,\"step\":0.01}\n",
        "    auto_download = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "    if fixed_seed == 0:\n",
        "      seed = random.randint(0, 18446744073709551615)\n",
        "    else:\n",
        "      seed = fixed_seed\n",
        "\n",
        "    print(\"Seed:\", seed)\n",
        "\n",
        "    cond, pooled = clip_f.encode_from_tokens(clip_f.tokenize(positive_prompt), return_pooled=True)\n",
        "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "    cond = FluxGuidance.append(cond, guidance)[0]\n",
        "    noise = RandomNoise.get_noise(seed)[0]\n",
        "    guider = BasicGuider.get_guider(unet_f, cond)[0]\n",
        "    sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
        "    sigmas = BasicScheduler.get_sigmas(unet_f, scheduler, steps, denoise)[0]\n",
        "\n",
        "    image = nodes.LoadImage().load_image(input_img)[0]\n",
        "    latent_image = ImageScaleToTotalPixels.upscale(image, \"lanczos\", 1.0)[0]\n",
        "    latent_image = VAEEncode.encode(vae, latent_image)[0]\n",
        "\n",
        "    sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
        "    model_management.soft_empty_cache()\n",
        "    decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"/content/flux_i2i_{seed}.png\")\n",
        "\n",
        "if auto_download:\n",
        "  files.download(f\"/content/flux_i2i_{seed}.png\")\n",
        "\n",
        "img = Image.open(f\"/content/flux_i2i_{seed}.png\")\n",
        "display(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}